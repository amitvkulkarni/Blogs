{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmR0-fYPb-Zn"
   },
   "source": [
    "# **AI Safety Playbook | Essential Steps to Ensure Your AI Stays Safe and Sound**\n",
    "#### **A comprehensive guide to implementing effective safety measures in AI-powered applications — covering everything from content filtering to access management and response validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Why AI Safety Matters?**\n",
    "As AI technology continues to grow, so does the need for safety in AI-powered applications. Without proper safeguards, AI systems can produce harmful outcomes, including biased content, misinformation, and breaches of user privacy. These issues can damage user trust, harm brand reputation, and create legal and ethical risks for companies.\n",
    "\n",
    "AI safety measures help minimize risks by setting clear limits on how AI systems operate. Content filtering, for instance, blocks offensive language and harmful information, protecting users from inappropriate outputs. Access control restricts interactions with sensitive AI systems to authorized users only, while rate limiting and usage monitoring prevent misuse and system overload. Additional tools, such as prompt moderation and output validation, further improve the accuracy and dependability of AI responses, ensuring a secure and reliable experience for all users.\n",
    "\n",
    "This guide will cover the core safety measures that every business should consider when deploying AI, from content filtering to monitoring, creating a safer and more responsible AI ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Understanding AI Safety Guardrails**\n",
    "AI safety guardrails are essential systems designed to keep AI applications secure, ethical, and on track with their intended purpose. Just as road guardrails keep vehicles safely within boundaries, AI guardrails ensure models operate within safe limits. They are key in preventing harmful outcomes, such as biased responses or risky decisions.\n",
    "\n",
    "These guardrails use tools such as content filters, access controls, and output checks to promote responsible AI behavior and lower the risk of unexpected outcomes. By implementing these safety measures, developers can build AI systems that are more reliable and trustworthy, giving users confidence in their applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Input guardrails**\n",
    "When designing guardrails, it’s crucial to find the right balance between accuracy, latency, and cost. The goal is to maximize accuracy while minimizing the impact on both your budget and the user experience. The cost can be managed by using small language models or models like Llama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing input guardrails\n",
    "We will be using Open AI API and the ‘gpt-40-mini’ model in our implementation but other models can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8B8cW-IUcGrl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from google.colab import userdata\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "GPT_MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7E-Vf4UocGtr"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "bad_request = \"What is a penalty shoot out in football\"\n",
    "good_request = \"What are the different ways a batsman can get out in cricket game?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_14zWl3McG1-"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def get_chat_response(user_request):\n",
    "    print(\"Getting LLM response\")\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=GPT_MODEL, messages=messages, temperature=0.5\n",
    "    )\n",
    "    print(\"Got LLM response\")\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "async def topical_guardrail(user_request):\n",
    "    print(\"Checking topical guardrail\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Your role is to assess whether the user question is allowed or not. The allowed topics cricket game. If the topic is allowed, say 'allowed' otherwise say 'not_allowed'\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=GPT_MODEL, messages=messages, temperature=0\n",
    "    )\n",
    "\n",
    "    print(\"Got guardrail response\")\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "async def execute_chat_with_guardrail(user_request):\n",
    "    topical_guardrail_task = asyncio.create_task(topical_guardrail(user_request))\n",
    "    chat_task = asyncio.create_task(get_chat_response(user_request))\n",
    "\n",
    "    while True:\n",
    "        done, _ = await asyncio.wait(\n",
    "            [topical_guardrail_task, chat_task], return_when=asyncio.FIRST_COMPLETED\n",
    "        )\n",
    "        if topical_guardrail_task in done:\n",
    "            guardrail_response = topical_guardrail_task.result()\n",
    "            if guardrail_response == \"not_allowed\":\n",
    "                chat_task.cancel()\n",
    "                print(\"Topical guardrail triggered\")\n",
    "                return \"I can only talk about game of cricket.\"\n",
    "            elif chat_task in done:\n",
    "                chat_response = chat_task.result()\n",
    "                return chat_response\n",
    "        else:\n",
    "            await asyncio.sleep(0.1)  # sleep for a bit before checking the tasks again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SD30sBwTcG4E",
    "outputId": "dc07f06b-e5ef-4b50-8204-a1149fb71e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking topical guardrail\n",
      "Got guardrail response\n",
      "Getting LLM response\n",
      "Got LLM response\n",
      "In cricket, a batsman can be dismissed (get out) in several ways. Here are the most common methods:\n",
      "\n",
      "1. **Bowled**: The batsman is out bowled if the ball is delivered by the bowler and hits the stumps, dislodging the bails.\n",
      "\n",
      "2. **Caught**: A batsman is out caught if a fielder catches the ball on the full (without it bouncing) after the batsman hits it with the bat.\n",
      "\n",
      "3. **Leg Before Wicket (LBW)**: A batsman can be given out LBW if the ball hits any part of their body (usually the leg) before hitting the bat, provided certain conditions are met, such as the ball pitching in line or outside off stump and the batsman not offering a shot.\n",
      "\n",
      "4. **Run Out**: A batsman is out run out if they attempt a run but the fielding side successfully breaks the stumps with the ball before the batsman reaches the crease.\n",
      "\n",
      "5. **Stumped**: A batsman is out stumped if they step out of their crease to play a shot and the wicketkeeper breaks the stumps with the ball while they are out of their ground.\n",
      "\n",
      "6. **Hit Wicket**: A batsman is out hit wicket if they accidentally hit their own stumps with their bat or body while playing a shot or while taking a stance.\n",
      "\n",
      "7. **Handled the Ball**: A batsman is out handled the ball if they deliberately use their hand or glove to return the ball to the fielding side, preventing it from being caught or fielded.\n",
      "\n",
      "8. **Obstructing the Field**: A batsman is out obstructing the field if they deliberately obstruct a fielder by using their bat or body.\n",
      "\n",
      "9. **Timed Out**: A batsman can be given out timed out if they do not arrive at the crease within a specified time (usually three minutes) after the previous batsman has been dismissed.\n",
      "\n",
      "10. **Retired Out**: A batsman can be considered out if they retire from their innings and the reason is not accepted by the umpires.\n",
      "\n",
      "These are the main ways a batsman can be dismissed in cricket. Each method has specific rules and conditions that must be met for the dismissal to be valid.\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with the good request - this should go through\n",
    "response = await execute_chat_with_guardrail(good_request)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w98rcad7cG6m",
    "outputId": "d137ca57-ee8a-42f6-f2a5-3c5d36290a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking topical guardrail\n",
      "Got guardrail response\n",
      "Getting LLM response\n",
      "Got LLM response\n",
      "Topical guardrail triggered\n",
      "I can only talk about game of cricket.\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with the good request - this should get blocked\n",
    "response = await execute_chat_with_guardrail(bad_request)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLJotPP3bkyL"
   },
   "source": [
    "## **Output guardrails**\n",
    "In the previous section, we discussed input checks. In this section, we will check the output from LLM models. Unwanted content can be misleading, so output moderation is essential.\n",
    "\n",
    "We begin by setting a name of the domain that defines the type of content we want to moderate. Next, we provide clear criteria that specify what the content should and should not include. Instructions are given to help the LLM evaluate the content effectively. Finally, the LLM assigns a score between 1 and 5 based on the content’s compliance with the defined criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Implementing output guardrails**\n",
    "To keep things interesting, let’s look at a different example, such as “Obesity.” Here, our goal is to extend the input guardrails discussed earlier and add a second layer of moderation. This involves checking the response generated by the LLM model before it reaches the end user, ensuring the content is safe, relevant and aligns with intended guidelines.\n",
    "\n",
    "Our objective\n",
    "- **Restrict Query Scope**: If the user query is unrelated to obesity, the response will be blocked.\n",
    "- **Moderate Responses on Sensitive Topics**: For questions on specific medications or methods to reduce obesity, the response will be carefully moderated. The AI will avoid recommending any medications or procedures.\n",
    "- **Guardrail Scoring System**: Implement a scoring mechanism (1 to 5) for output guardrails. If the score exceeds the defined threshold, the response will be moderated. If the score is within the threshold, the response will be delivered as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqQ49EiKcG81"
   },
   "outputs": [],
   "source": [
    "domain = \"Obesity\"\n",
    "\n",
    "health_advice_criteria = \"\"\"\n",
    "Assess the presence of explicit recommendation on obesity in the content.\n",
    "The content should contain only general definition, description of the domain and not specific medicines to purchase.\"\"\"\n",
    "\n",
    "health_advice_steps = \"\"\"\n",
    "1. Read the content and the criteria carefully.\n",
    "2. Assess how much explicit content on domain in general is contained in the content.\n",
    "3. Assign an advice score from 1 to 5, with 1 being generic description, definition, and 5 being explicit advice on medications or medicines.\n",
    "\"\"\"\n",
    "\n",
    "moderation_system_prompt = \"\"\"\n",
    "You are a moderation assistant. Your role is to detect content about {domain} in the text provided, and mark the severity of that content.\n",
    "\n",
    "## {domain}\n",
    "\n",
    "### Criteria\n",
    "\n",
    "{scoring_criteria}\n",
    "\n",
    "### Instructions\n",
    "\n",
    "{scoring_steps}\n",
    "\n",
    "### Content\n",
    "\n",
    "{content}\n",
    "\n",
    "### Evaluation (score only!)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our configurations in place, let’s define functions to implement each of our objectives, including topical guardrails, and moderation guardrails, and execute both for the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psC91sUbcG-k"
   },
   "outputs": [],
   "source": [
    "async def topical_guardrail(user_request):\n",
    "    print(\"Checking topical guardrail\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Your role is to assess whether the user question is allowed or not. The allowed topic is obesity. If the topic is allowed, say 'allowed' otherwise say 'not_allowed'\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=GPT_MODEL, messages=messages, temperature=0\n",
    "    )\n",
    "\n",
    "    print(\"Got guardrail response\")\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "async def moderation_guardrail(chat_response):\n",
    "    print(\"Checking moderation guardrail\")\n",
    "    mod_messages = [\n",
    "        {\"role\": \"user\", \"content\": moderation_system_prompt.format(\n",
    "            domain=domain,\n",
    "            scoring_criteria=health_advice_criteria,\n",
    "            scoring_steps=health_advice_steps,\n",
    "            content=chat_response\n",
    "        )},\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=GPT_MODEL, messages=mod_messages, temperature=0\n",
    "    )\n",
    "    print(\"Got moderation response\")\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "async def execute_all_guardrails(user_request):\n",
    "    topical_guardrail_task = asyncio.create_task(topical_guardrail(user_request))\n",
    "    chat_task = asyncio.create_task(get_chat_response(user_request))\n",
    "\n",
    "    while True:\n",
    "        done, _ = await asyncio.wait(\n",
    "            [topical_guardrail_task, chat_task], return_when=asyncio.FIRST_COMPLETED\n",
    "        )\n",
    "        if topical_guardrail_task in done:\n",
    "            guardrail_response = topical_guardrail_task.result()\n",
    "            print(f'****{guardrail_response}******')\n",
    "            if guardrail_response == \"not_allowed\":\n",
    "                chat_task.cancel()\n",
    "                print(\"Topical guardrail triggered\")\n",
    "                return f\"I can only talk about {domain} and not on other topics\"\n",
    "            elif chat_task in done:\n",
    "                chat_response = chat_task.result()\n",
    "                moderation_response = await moderation_guardrail(chat_response)\n",
    "\n",
    "                if int(moderation_response) >= 3:\n",
    "                    print(f\"Moderation guardrail flagged with a score of {int(moderation_response)}\")\n",
    "                    return \"Sorry, we're not permitted to give prescriptions or medication advice. I can help you with any general queries you might have.\"\n",
    "\n",
    "                else:\n",
    "                    print('Passed moderation')\n",
    "                    print(f'-'*30)\n",
    "                    return chat_response\n",
    "        else:\n",
    "            await asyncio.sleep(0.1)  # sleep for a bit before checking the tasks again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8uKckkdcHA9"
   },
   "outputs": [],
   "source": [
    "# Adding a request that should pass both our topical guardrail and our moderation guardrail\n",
    "request_1 = 'Define obesity?'\n",
    "request_2 = 'What are the medications that can be consumed to reduce obesity?'\n",
    "request_3 = 'What are some advice you can give to a somone with obesity?'\n",
    "request_4 = 'What causes liver cirrhosis?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Expected outcome from the LLM**\n",
    "\n",
    "- **Request 1**: Generate the response as it meets the criteria of both input and output guardrails\n",
    "- **Request 2 & 3**: Block the response from the LLM as it doesn’t meet the output criteria\n",
    "- **Request 4**: Block the response as it doesn’t meet the input guardrail criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gU1-9stbyRA",
    "outputId": "49adf01e-17aa-41a1-ce57-f857c4585a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking topical guardrail\n",
      "Got guardrail response\n",
      "Getting LLM response\n",
      "Got LLM response\n",
      "****allowed******\n",
      "Checking moderation guardrail\n",
      "Got moderation response\n",
      "Passed moderation\n",
      "------------------------------\n",
      "Obesity is a medical condition characterized by an excessive accumulation of body fat that presents a risk to health. It is typically assessed using the Body Mass Index (BMI), which is calculated by dividing a person's weight in kilograms by the square of their height in meters. A BMI of 30 or higher is generally classified as obesity.\n",
      "\n",
      "Obesity can lead to various health issues, including heart disease, diabetes, hypertension, certain types of cancer, and other chronic conditions. It is often influenced by a combination of genetic, behavioral, environmental, and metabolic factors. Managing obesity typically involves lifestyle changes such as improved diet, increased physical activity, and, in some cases, medical interventions.\n",
      "\n",
      "\n",
      "\n",
      "Checking topical guardrail\n",
      "Got guardrail response\n",
      "Getting LLM response\n",
      "Got LLM response\n",
      "****allowed******\n",
      "Checking moderation guardrail\n",
      "Got moderation response\n",
      "Moderation guardrail flagged with a score of 5\n",
      "Sorry, we're not permitted to give prescriptions or medication advice. I can help you with any general queries you might have.\n",
      "\n",
      "\n",
      "\n",
      "Checking topical guardrail\n",
      "Got guardrail response\n",
      "Getting LLM response\n",
      "Got LLM response\n",
      "****allowed******\n",
      "Checking moderation guardrail\n",
      "Got moderation response\n",
      "Moderation guardrail flagged with a score of 3\n",
      "Sorry, we're not permitted to give prescriptions or medication advice. I can help you with any general queries you might have.\n",
      "\n",
      "\n",
      "\n",
      "Checking topical guardrail\n",
      "Got guardrail response\n",
      "Getting LLM response\n",
      "Got LLM response\n",
      "****not_allowed******\n",
      "Topical guardrail triggered\n",
      "I can only talk about Obesity and not on other topics\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tests = [request_1, request_2, request_3, request_4]\n",
    "\n",
    "for test in tests:\n",
    "    result = await execute_all_guardrails(test)\n",
    "    print(result)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output matches our expectations, showing that the system or process is working as intended. This indicates that the variables and parameters we’ve set are working together to produce the desired results. The consistent output confirms that the methodology we applied is effective and that the expected patterns, trends, or responses are being generated. In short, everything is on track, and the system is performing as expected, which is a clear sign of its stability and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**\n",
    "In this blog, we explored the essential role guardrails play in maintaining AI safety. These safeguards are designed to block harmful or inappropriate content, ensuring AI systems act ethically and reliably. We discussed how input and output guardrails work together to secure AI behavior and emphasized the importance of balancing accuracy, latency, and cost when implementing these controls. Additionally, we highlighted how asynchronous design principles enable guardrails to scale effectively, minimizing any impact on the user experience.\n",
    "\n",
    "AI safety goes beyond basic compliance; it’s about building trustworthy and dependable AI applications. By investing in strong AI safety measures, companies protect against risks and enhance the overall user experience, fostering a safer and more positive AI environment."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b00d2d4326b4944bede8c46974ae561": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_775d684bbddc4091b047a4d326b43350",
      "placeholder": "​",
      "style": "IPY_MODEL_6d063f066fbe4440ae336d4dbcd79746",
      "value": " 5/5 [00:05&lt;00:00,  1.19it/s]"
     }
    },
    "224b6d265c8d447e94ec2d0f8e9461ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "335c5bc888584cd48997536d38a48d67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4973fd3886bf438aaf4242df8723dcb0",
      "placeholder": "​",
      "style": "IPY_MODEL_e7638975d023451e9d5e741a5ba3d6a5",
      "value": "Evaluating: 100%"
     }
    },
    "4020eaf702e64e11b9fd26a8aa3ef705": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4973fd3886bf438aaf4242df8723dcb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fe3fe8f951844e1a3edd7720e0a1dd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb8eee445aa142899655c7adadfe421b",
       "IPY_MODEL_f6881a867fe0475ea2fa0b9fa1a3555f",
       "IPY_MODEL_b0be78e162944e529a5a6bcad2ec07d5"
      ],
      "layout": "IPY_MODEL_4020eaf702e64e11b9fd26a8aa3ef705"
     }
    },
    "68a02378db33404fab0de72708ca524e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68b0c9bcccf0452b80c8c09d7463bbf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_335c5bc888584cd48997536d38a48d67",
       "IPY_MODEL_d5c4dbccdb4e45ada759ceead7f4b3d2",
       "IPY_MODEL_0b00d2d4326b4944bede8c46974ae561"
      ],
      "layout": "IPY_MODEL_9986ea6e473a42b399bf6de92e6731f6"
     }
    },
    "68ef6aeb68f74ffaad4c7d4e5d27cc0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d063f066fbe4440ae336d4dbcd79746": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "775d684bbddc4091b047a4d326b43350": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8437d18c56414d92990b7983d96e89dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84afe573d41c44a1a8dad4d172c92f2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88091ea2a535457c96e2e1f77851ca5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9986ea6e473a42b399bf6de92e6731f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0be78e162944e529a5a6bcad2ec07d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8437d18c56414d92990b7983d96e89dc",
      "placeholder": "​",
      "style": "IPY_MODEL_d4ace0641567453cab53962d60580e63",
      "value": " 12/12 [00:07&lt;00:00,  1.69it/s]"
     }
    },
    "d0ddfa56dcf84e3cb21ef0a32216944b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4ace0641567453cab53962d60580e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5c4dbccdb4e45ada759ceead7f4b3d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68a02378db33404fab0de72708ca524e",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88091ea2a535457c96e2e1f77851ca5b",
      "value": 5
     }
    },
    "e7638975d023451e9d5e741a5ba3d6a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6881a867fe0475ea2fa0b9fa1a3555f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84afe573d41c44a1a8dad4d172c92f2d",
      "max": 12,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_224b6d265c8d447e94ec2d0f8e9461ab",
      "value": 12
     }
    },
    "fb8eee445aa142899655c7adadfe421b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68ef6aeb68f74ffaad4c7d4e5d27cc0e",
      "placeholder": "​",
      "style": "IPY_MODEL_d0ddfa56dcf84e3cb21ef0a32216944b",
      "value": "Evaluating: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
