{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-WVupyy3fy_"
      },
      "source": [
        "# **Your Agentic AI Just Went Rogue. How can you Hit¬†Rewind?**\n",
        "#### Learn how to build Agentic AI that recovers from errors and lets you rewind to any point, ensuring flawless operation and deep insights into every¬†decision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Did you know that even the most advanced AI agents, without proper safeguards, can be as fragile as a house of cards? Imagine a complex multi-step AI workflow, perhaps assisting customers or automating intricate business processes.¬†\n",
        "#### What happens when a single API call fails, or an unexpected input derails the entire operation? Traditionally, you'd be left scrambling, losing valuable context and potentially starting from scratch.¬†\n",
        "#### We've all been there, staring at a stack trace, wishing we could just \"go back in time\" to see what went wrong, or that the system could simply pick up where it left off after a hiccup.\n",
        "#### This blog explores LangGraph's fault tolerance and time travel features, which offer a robust safety net for AI applications, simplify debugging, enable graceful recovery, and provide unprecedented control."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm2JfSyR3qZL"
      },
      "outputs": [],
      "source": [
        "# !pip install langgraph langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_g0YvrO3iWz"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import TypedDict\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.checkpoint.memory import InMemorySaver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass()\n",
        "\n",
        "llm = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5Ebqc3CDm5e"
      },
      "outputs": [],
      "source": [
        "class CountryState(TypedDict):\n",
        "\n",
        "    country: str\n",
        "    capital: str\n",
        "    brief: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmBmq4G_Dxfk"
      },
      "outputs": [],
      "source": [
        "def fetch_capital(state: CountryState):\n",
        "\n",
        "    prompt = f'Find the capital of the country {state[\"country\"]}'\n",
        "    response = llm.invoke(prompt).content\n",
        "\n",
        "    return {'capital': response}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WMNe9QJEGaN"
      },
      "outputs": [],
      "source": [
        "def generate_brief(state: CountryState):\n",
        "\n",
        "    prompt = f'write an brief on the capital in 25 words - {state[\"capital\"]}'\n",
        "    response = llm.invoke(prompt).content\n",
        "\n",
        "    return {'brief': response}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIvfa-mD3ytL"
      },
      "outputs": [],
      "source": [
        "graph = StateGraph(CountryState)\n",
        "\n",
        "graph.add_node('fetch_capital', fetch_capital)\n",
        "graph.add_node('generate_brief', generate_brief)\n",
        "\n",
        "graph.add_edge(START, 'fetch_capital')\n",
        "graph.add_edge('fetch_capital', 'generate_brief')\n",
        "graph.add_edge('generate_brief', END)\n",
        "\n",
        "checkpointer = InMemorySaver()\n",
        "\n",
        "workflow = graph.compile(checkpointer=checkpointer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZZoIbw73yvu",
        "outputId": "6a60e37d-a13a-4317-d7b6-2decd8d32ca0"
      },
      "outputs": [],
      "source": [
        "config1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "workflow.invoke({'country':'India'}, config=config1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MYuwbNT3yxz",
        "outputId": "2fccfe1b-8674-4799-da66-57dae7f49e4e"
      },
      "outputs": [],
      "source": [
        "workflow.get_state(config1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCZr5fCX3y0D",
        "outputId": "fbdbddcc-7eee-4c0e-96f7-3cda1ccb3d16"
      },
      "outputs": [],
      "source": [
        "list(workflow.get_state_history(config1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSiVjucBHPBI"
      },
      "source": [
        "# **Updating the state**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv31zLYHGifq",
        "outputId": "df855ce3-f4f7-4506-cca4-b5a3692f0d17"
      },
      "outputs": [],
      "source": [
        "workflow.update_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f071f29-b1e2-6b1c-8000-0ada42529435\", \"checkpoint_ns\": \"\"}}, {'country':'Russia'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7qV-FVCGih4",
        "outputId": "48795184-3da3-43cb-f672-e427d14973a1"
      },
      "outputs": [],
      "source": [
        "list(workflow.get_state_history(config1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVCQ11TwIHan",
        "outputId": "551bb751-1de9-47a2-f41c-e41c0b36b737"
      },
      "outputs": [],
      "source": [
        "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f071f2f-8a5e-6a2a-8001-4d8b40dd6b8d\"}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTpawXvyIHdL",
        "outputId": "89e28c3a-2804-41c3-8c63-23598b2c9559"
      },
      "outputs": [],
      "source": [
        "list(workflow.get_state_history(config1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HxZ9zHN3-lk"
      },
      "source": [
        "# **Time Travel**\n",
        "\n",
        "#### LangGraph's time travel feature, powered by robust checkpointing, enables users to rewind time to understand complex AI agent decisions. It allows inspection of agent state, replaying specific steps, and even \"forking\" execution to explore alternative paths, making it a valuable tool in complex AI systems.\n",
        "#### Gaining unparalleled visibility into your AI's \"thought process\" is not just about traditional debugging; it involves imagining an agent making suboptimal decisions. With time travel, you can:\n",
        "#### * Review historical states: See the exact state (messages, tools called, data) at each node execution.\n",
        "#### * Replay from any point: Restart the workflow from a specific checkpoint, perhaps after tweaking a prompt or a tool's logic, to see if the outcome changes.\n",
        "\n",
        "#### First, let's take a look at the workflow's state. We asked for the capital of India, and as you can see, the result came back just as we expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxCLWzCJ4ArD",
        "outputId": "fe58203e-ad4e-4596-c36e-033cb11eb942"
      },
      "outputs": [],
      "source": [
        "workflow.get_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f071cba-7c01-67ea-8004-3ccaef6e7005\"}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_K_ZFKqHAuA",
        "outputId": "f0d8cd3c-37ef-4e63-e455-9dc69235fe4f"
      },
      "outputs": [],
      "source": [
        "workflow.get_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f071cba-7645-6f32-8003-82b780af153e\"}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lix2xLx17RSy"
      },
      "source": [
        "# **Fault Tolerance**\n",
        "\n",
        "#### LangGraph offers built-in fault tolerance in AI workflows, allowing agents to continue from where they left off. This is achieved through intelligent state management and checkpointing, which maintains a dynamic, shared state that updates with every step in the workflow. This state can hold vital data, conversation history, search results, or complex decision stages.\n",
        "#### LangGraph's checkpointing feature saves your AI's progress at key moments. This keeps your agent from collapsing, so it can pick up right where it left off even after a failure. This reduces wasted computation, smooths the user experience, and makes AI applications more robust. This feature is a significant improvement over traditional systems that often require a full restart, losing all progress.\n",
        "#### To show this in action, we'll simulate a failure. We'll deliberately interrupt the workflow, then restart it later. This will demonstrate how LangGraph doesn't just start over from the beginning but resumes right where it left off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeRMvnNK4A0C"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from typing import TypedDict\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpq0cQRt4A2K"
      },
      "outputs": [],
      "source": [
        "# 1. Define the state\n",
        "class CrashState(TypedDict):\n",
        "    input: str\n",
        "    step1: str\n",
        "    step2: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHo_5HG14A4b"
      },
      "outputs": [],
      "source": [
        "# 2. Define steps\n",
        "def step_1(state: CrashState) -> CrashState:\n",
        "    print(\"‚úÖ Step 1 executed\")\n",
        "    return {\"Stage  1\": \"Completed\", \"input\": state[\"input\"]}\n",
        "\n",
        "def step_2(state: CrashState) -> CrashState:\n",
        "    print(\"‚è≥ Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\")\n",
        "    time.sleep(50)  # Simulate long-running hang\n",
        "    return {\"Stage 2\": \"Completed\"}\n",
        "\n",
        "def step_3(state: CrashState) -> CrashState:\n",
        "    print(\"‚úÖ Stage 3 executed\")\n",
        "    return {\"Completed\": True}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddE4HHuU-q76"
      },
      "outputs": [],
      "source": [
        "# 3. Build the graph\n",
        "builder = StateGraph(CrashState)\n",
        "builder.add_node(\"step_1\", step_1)\n",
        "builder.add_node(\"step_2\", step_2)\n",
        "builder.add_node(\"step_3\", step_3)\n",
        "\n",
        "builder.set_entry_point(\"step_1\")\n",
        "builder.add_edge(\"step_1\", \"step_2\")\n",
        "builder.add_edge(\"step_2\", \"step_3\")\n",
        "builder.add_edge(\"step_3\", END)\n",
        "\n",
        "checkpointer = InMemorySaver()\n",
        "graph = builder.compile(checkpointer=checkpointer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oaw8dvd-q-Z",
        "outputId": "811ae63d-cf4c-440b-c256-bddb18c68dfb"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    print(\"‚ñ∂Ô∏è Running graph: Please manually interrupt during Step 2...\")\n",
        "    graph.invoke({\"input\": \"start\"}, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
        "except KeyboardInterrupt:\n",
        "    print(\"‚ùå Kernel manually interrupted (crash simulated).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylW5SMaTND_j",
        "outputId": "f5498421-71f8-4230-99f4-ed0257a2d12c"
      },
      "outputs": [],
      "source": [
        "list(graph.get_state_history({\"configurable\": {\"thread_id\": 'thread-1'}}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvq2Mt8j-rAp",
        "outputId": "5e2bd61c-2430-44b7-b9d3-2815fc690a5d"
      },
      "outputs": [],
      "source": [
        "# 6. Re-run to show fault-tolerant resume\n",
        "print(\"\\nüîÅ Re-running the graph to demonstrate fault tolerance...\")\n",
        "final_state = graph.invoke(None, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
        "print(\"\\n‚úÖ Final State:\", final_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Conclusion**\n",
        "#### LangGraph is a powerful tool that revolutionizes the process of building AI agents. Its error handling and time travel features enable the creation of complex systems that resist problems and allow for thorough review of past actions.¬†\n",
        "#### This provides deep insight and control, enabling agents to recover smoothly and retain crucial information. LangGraph also aids in analyzing AI decisions, boosting performance, and tracking compliance steps, allowing for more efficient AI development.\n",
        "#### I highly encourage you to explore LangGraph's official documentation, experiment with the code examples we've discussed, and even try building a small, fault-tolerant agent of your own. Let me know in the comments about your experiments and learnings."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14608cc92bdc45c2b176d1b405af3faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e752861a0943428e9367a85386fe6828",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4f33e428ff4d452bb021b7235af702b0",
            "value": "Batches:‚Äá100%"
          }
        },
        "1740d0ba48e249469e5984cccadf53e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44cb942fcd0247619cbeabdfcb58b20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_982a82a1ab71420c9f2e3a3c0c25cbc6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d833aff6a7af411b8155bb5e46a3c76c",
            "value": 2
          }
        },
        "4f33e428ff4d452bb021b7235af702b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "552e4c86681e44f3a156238358266a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14608cc92bdc45c2b176d1b405af3faa",
              "IPY_MODEL_44cb942fcd0247619cbeabdfcb58b20d",
              "IPY_MODEL_66fa10b6780c4f51b20d27bc8d93153d"
            ],
            "layout": "IPY_MODEL_1740d0ba48e249469e5984cccadf53e2"
          }
        },
        "5bed5ce4aa424c05947e46bca92a552c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66fa10b6780c4f51b20d27bc8d93153d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be6b838b9dc842e7924d831286ccf016",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5bed5ce4aa424c05947e46bca92a552c",
            "value": "‚Äá2/2‚Äá[00:00&lt;00:00,‚Äá‚Äá2.41it/s]"
          }
        },
        "982a82a1ab71420c9f2e3a3c0c25cbc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be6b838b9dc842e7924d831286ccf016": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d833aff6a7af411b8155bb5e46a3c76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e752861a0943428e9367a85386fe6828": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
